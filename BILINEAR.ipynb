{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9164c48-5d20-4d2e-9c6b-44e586ccc357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib as mpl\n",
    "import cv2\n",
    "import time\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from keras.initializers import glorot_normal\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "   tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from matplotlib import pyplot\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ce9061-2116-4b32-93c1-44b457992305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculates dot product of x[0] and x[1] for mini_batch \n",
    "\n",
    "Assuming both have same size and shape\n",
    "\n",
    "@param\n",
    "x -> [ (size_minibatch, total_pixels, size_filter), (size_minibatch, total_pixels, size_filter) ]\n",
    "\n",
    "\"\"\"\n",
    "def dot_product(x):\n",
    "\n",
    "    return keras.backend.batch_dot(x[0], x[1], axes=[1,1]) / x[0].get_shape().as_list()[1] \n",
    "\n",
    "\"\"\"\n",
    "Calculate signed square root\n",
    "\n",
    "@param\n",
    "x -> a tensor\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def signed_sqrt(x):\n",
    "\n",
    "    return keras.backend.sign(x) * keras.backend.sqrt(keras.backend.abs(x) + 1e-9)\n",
    "\n",
    "\"\"\"\n",
    "Calculate L2-norm\n",
    "\n",
    "@param\n",
    "x -> a tensor\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def L2_norm(x, axis=-1):\n",
    "\n",
    "    return keras.backend.l2_normalize(x, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56cbfbc9-dc9b-4c30-9758-400a8de9601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "    Take outputs of last layer of VGG and load it into Lambda layer which calculates outer product.\n",
    "    \n",
    "    Here both bi-linear branches have same shape.\n",
    "    \n",
    "    z -> output shape tuple\n",
    "    x -> outpur og VGG tensor\n",
    "    y -> copy of x as we modify x, we use x, y for outer product.\n",
    "    \n",
    "'''\n",
    "\n",
    "def build_model():\n",
    "    tensor_input = keras.layers.Input(shape=[150,150,3])\n",
    "\n",
    "#   load pre-trained model\n",
    "    tensor_input = keras.layers.Input(shape=[150,150,3])\n",
    "    \n",
    "\n",
    "    \n",
    "    model_detector = keras.applications.vgg16.VGG16(\n",
    "                            input_tensor=tensor_input, \n",
    "                            include_top=False,\n",
    "                            weights='imagenet')\n",
    "    \n",
    "    model_detector2 = keras.applications.vgg16.VGG16(\n",
    "                            input_tensor=tensor_input, \n",
    "                            include_top=False,\n",
    "                            weights='imagenet')\n",
    "    \n",
    "    \n",
    "    model_detector2 = keras.models.Sequential(layers=model_detector2.layers)\n",
    "  \n",
    "    for i, layer in enumerate(model_detector2.layers):\n",
    "        layer._name = layer.name  +\"_second\"\n",
    "\n",
    "    model2 = keras.models.Model(inputs=[tensor_input], outputs = [model_detector2.layers[-1].output])\n",
    "                       \n",
    "    x = model_detector.layers[17].output\n",
    "    z = model_detector.layers[17].output_shape\n",
    "    y = model2.layers[17].output\n",
    "    \n",
    "    print(model_detector.summary())\n",
    "    \n",
    "    print(model2.summary())\n",
    "#   rehape to (batch_size, total_pixels, filter_size)\n",
    "    x = keras.layers.Reshape([z[1] * z[2] , z[-1]])(x)\n",
    "        \n",
    "    y = keras.layers.Reshape([z[1] * z[2] , z[-1]])(y)\n",
    "    \n",
    "#   outer products of x, y\n",
    "    x = keras.layers.Lambda(dot_product)([x, y])\n",
    "    \n",
    "#   rehape to (batch_size, filter_size_vgg_last_layer*filter_vgg_last_layer)\n",
    "    x = keras.layers.Reshape([z[-1]*z[-1]])(x)\n",
    "        \n",
    "#   signed_sqrt\n",
    "    x = keras.layers.Lambda(signed_sqrt)(x)\n",
    "        \n",
    "#   L2_norm\n",
    "    x = keras.layers.Lambda(L2_norm)(x)\n",
    "\n",
    "#   FC-Layer\n",
    "\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "            \n",
    "    x = keras.layers.Dense(units=258, \n",
    "                           kernel_regularizer=keras.regularizers.l2(0.0),\n",
    "                           kernel_initializer=initializer)(x)\n",
    "\n",
    "    tensor_prediction = keras.layers.Activation(\"softmax\")(x)\n",
    "\n",
    "    model_bilinear = keras.models.Model(inputs=[tensor_input],\n",
    "                                        outputs=[tensor_prediction])\n",
    "    \n",
    "    \n",
    "#   Freeze VGG layers\n",
    "    for layer in model_detector.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "\n",
    "    sgd = keras.optimizers.SGD(lr=1.0, \n",
    "                               decay=0.0,\n",
    "                               momentum=0.9)\n",
    "\n",
    "    model_bilinear.compile(loss=\"categorical_crossentropy\", \n",
    "                           optimizer=sgd,\n",
    "                           metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    model_bilinear.summary()\n",
    "    \n",
    "    return model_bilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67fea6f2-836d-462f-bd37-496a3f16e183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1_second (Conv2D) (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2_second (Conv2D) (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool_second (MaxPooli (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1_second (Conv2D) (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2_second (Conv2D) (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool_second (MaxPooli (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1_second (Conv2D) (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2_second (Conv2D) (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3_second (Conv2D) (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool_second (MaxPooli (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1_second (Conv2D) (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2_second (Conv2D) (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3_second (Conv2D) (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool_second (MaxPooli (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1_second (Conv2D) (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2_second (Conv2D) (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3_second (Conv2D) (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool_second (MaxPooli (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_40 (InputLayer)           [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 150, 150, 64) 1792        input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_second (Conv2D)    (None, 150, 150, 64) 1792        input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 150, 150, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_second (Conv2D)    (None, 150, 150, 64) 36928       block1_conv1_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 75, 75, 64)   0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool_second (MaxPooling2 (None, 75, 75, 64)   0           block1_conv2_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 75, 75, 128)  73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_second (Conv2D)    (None, 75, 75, 128)  73856       block1_pool_second[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 75, 75, 128)  147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_second (Conv2D)    (None, 75, 75, 128)  147584      block2_conv1_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 37, 37, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool_second (MaxPooling2 (None, 37, 37, 128)  0           block2_conv2_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 37, 37, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_second (Conv2D)    (None, 37, 37, 256)  295168      block2_pool_second[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 37, 37, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_second (Conv2D)    (None, 37, 37, 256)  590080      block3_conv1_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 37, 37, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_second (Conv2D)    (None, 37, 37, 256)  590080      block3_conv2_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_second (MaxPooling2 (None, 18, 18, 256)  0           block3_conv3_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 18, 18, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_second (Conv2D)    (None, 18, 18, 512)  1180160     block3_pool_second[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 18, 18, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_second (Conv2D)    (None, 18, 18, 512)  2359808     block4_conv1_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 18, 18, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_second (Conv2D)    (None, 18, 18, 512)  2359808     block4_conv2_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 9, 9, 512)    0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool_second (MaxPooling2 (None, 9, 9, 512)    0           block4_conv3_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 9, 9, 512)    2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_second (Conv2D)    (None, 9, 9, 512)    2359808     block4_pool_second[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 9, 9, 512)    2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_second (Conv2D)    (None, 9, 9, 512)    2359808     block5_conv1_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 9, 9, 512)    2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_second (Conv2D)    (None, 9, 9, 512)    2359808     block5_conv2_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 81, 512)      0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_20 (Reshape)            (None, 81, 512)      0           block5_conv3_second[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 512, 512)     0           reshape_19[0][0]                 \n",
      "                                                                 reshape_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 262144)       0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 262144)       0           reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 262144)       0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 258)          67633410    lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 258)          0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 97,062,786\n",
      "Trainable params: 82,348,098\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\project\\src\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b684a981-ebef-4bdc-b26d-e7b25647e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(epochs):\n",
    "\n",
    "    hist = model.fit_generator(\n",
    "                train_generator, \n",
    "                epochs=epochs, \n",
    "                validation_data=val_generator,\n",
    "                workers=3,\n",
    "                verbose=1\n",
    "            )\n",
    "        \n",
    "    model.save_weights(\"./bilinear_weights/val_acc_\" + hist.history['val_categorical_accuracy'][-1] +\"_\"+ str(epochs)+ \".h5\")\n",
    "    \n",
    "    return hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f50522af-899e-4ab0-ae66-17f5106c11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbe2b5ac-fde1-4086-9aa7-ef4a8b9ebc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6965 images belonging to 258 classes.\n",
      "Found 1290 images belonging to 258 classes.\n",
      "Found 2064 images belonging to 258 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../nut_snacks/dataset_split/train',\n",
    "        target_size=(150, 150),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        subset='training',\n",
    "        class_mode='categorical')\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "        '../nut_snacks/dataset_split/val',\n",
    "        target_size=(150, 150),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        subset='training',\n",
    "        class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '../nut_snacks/dataset_split/test',\n",
    "        target_size=(150, 150),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle = False,\n",
    "        class_mode=None,\n",
    "        batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "068e07bc-5c64-4f85-a286-8e987a78da21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/20\n",
      "218/218 [==============================] - 80s 348ms/step - loss: 5.5490 - categorical_accuracy: 0.0084 - val_loss: 5.0909 - val_categorical_accuracy: 0.0535\n",
      "Epoch 2/20\n",
      "218/218 [==============================] - 22s 98ms/step - loss: 5.0199 - categorical_accuracy: 0.0805 - val_loss: 4.5553 - val_categorical_accuracy: 0.2008\n",
      "Epoch 3/20\n",
      "218/218 [==============================] - 21s 96ms/step - loss: 4.5126 - categorical_accuracy: 0.2078 - val_loss: 4.0710 - val_categorical_accuracy: 0.3426\n",
      "Epoch 4/20\n",
      "218/218 [==============================] - 21s 96ms/step - loss: 4.0530 - categorical_accuracy: 0.3250 - val_loss: 3.6810 - val_categorical_accuracy: 0.3984\n",
      "Epoch 5/20\n",
      "218/218 [==============================] - 21s 96ms/step - loss: 3.6557 - categorical_accuracy: 0.4202 - val_loss: 3.3430 - val_categorical_accuracy: 0.4736\n",
      "Epoch 6/20\n",
      "218/218 [==============================] - 22s 98ms/step - loss: 3.3100 - categorical_accuracy: 0.4779 - val_loss: 3.0262 - val_categorical_accuracy: 0.5256\n",
      "Epoch 7/20\n",
      "218/218 [==============================] - 22s 99ms/step - loss: 3.0142 - categorical_accuracy: 0.5355 - val_loss: 2.7733 - val_categorical_accuracy: 0.5504\n",
      "Epoch 8/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 2.7875 - categorical_accuracy: 0.5616 - val_loss: 2.5675 - val_categorical_accuracy: 0.5659\n",
      "Epoch 9/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 2.5713 - categorical_accuracy: 0.6021 - val_loss: 2.3676 - val_categorical_accuracy: 0.6078\n",
      "Epoch 10/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 2.3778 - categorical_accuracy: 0.6278 - val_loss: 2.2185 - val_categorical_accuracy: 0.6217\n",
      "Epoch 11/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 2.2328 - categorical_accuracy: 0.6372 - val_loss: 2.0879 - val_categorical_accuracy: 0.6388\n",
      "Epoch 12/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 2.0704 - categorical_accuracy: 0.6840 - val_loss: 1.9634 - val_categorical_accuracy: 0.6434\n",
      "Epoch 13/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.9461 - categorical_accuracy: 0.6968 - val_loss: 1.8671 - val_categorical_accuracy: 0.6798\n",
      "Epoch 14/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.8197 - categorical_accuracy: 0.7140 - val_loss: 1.7712 - val_categorical_accuracy: 0.6946\n",
      "Epoch 15/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.7682 - categorical_accuracy: 0.7161 - val_loss: 1.6712 - val_categorical_accuracy: 0.6860\n",
      "Epoch 16/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.6696 - categorical_accuracy: 0.7323 - val_loss: 1.6212 - val_categorical_accuracy: 0.7062\n",
      "Epoch 17/20\n",
      "218/218 [==============================] - 22s 99ms/step - loss: 1.6067 - categorical_accuracy: 0.7398 - val_loss: 1.5472 - val_categorical_accuracy: 0.7271\n",
      "Epoch 18/20\n",
      "218/218 [==============================] - 23s 104ms/step - loss: 1.5304 - categorical_accuracy: 0.7570 - val_loss: 1.4940 - val_categorical_accuracy: 0.7147loss: 1\n",
      "Epoch 19/20\n",
      "218/218 [==============================] - 22s 102ms/step - loss: 1.4706 - categorical_accuracy: 0.7515 - val_loss: 1.4418 - val_categorical_accuracy: 0.7248\n",
      "Epoch 20/20\n",
      "218/218 [==============================] - 22s 98ms/step - loss: 1.3948 - categorical_accuracy: 0.7694 - val_loss: 1.3960 - val_categorical_accuracy: 0.7310\n"
     ]
    }
   ],
   "source": [
    "hist =train_model(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2e9da32-a0f0-46a5-aec6-6d166dcc49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/20\n",
      "218/218 [==============================] - 21s 96ms/step - loss: 1.3571 - categorical_accuracy: 0.7756 - val_loss: 1.3495 - val_categorical_accuracy: 0.7357\n",
      "Epoch 2/20\n",
      "218/218 [==============================] - 21s 96ms/step - loss: 1.3064 - categorical_accuracy: 0.7844 - val_loss: 1.3028 - val_categorical_accuracy: 0.7434\n",
      "Epoch 3/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.2710 - categorical_accuracy: 0.7799 - val_loss: 1.2608 - val_categorical_accuracy: 0.7558\n",
      "Epoch 4/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.2220 - categorical_accuracy: 0.7987 - val_loss: 1.2396 - val_categorical_accuracy: 0.7612\n",
      "Epoch 5/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.1944 - categorical_accuracy: 0.7964 - val_loss: 1.2317 - val_categorical_accuracy: 0.7426\n",
      "Epoch 6/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.1556 - categorical_accuracy: 0.8052 - val_loss: 1.1720 - val_categorical_accuracy: 0.7651\n",
      "Epoch 7/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.1307 - categorical_accuracy: 0.8033 - val_loss: 1.1522 - val_categorical_accuracy: 0.7729\n",
      "Epoch 8/20\n",
      "218/218 [==============================] - 22s 98ms/step - loss: 1.1082 - categorical_accuracy: 0.8093 - val_loss: 1.1307 - val_categorical_accuracy: 0.7705\n",
      "Epoch 9/20\n",
      "218/218 [==============================] - 21s 98ms/step - loss: 1.0749 - categorical_accuracy: 0.8177 - val_loss: 1.1106 - val_categorical_accuracy: 0.7682\n",
      "Epoch 10/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.0399 - categorical_accuracy: 0.8200 - val_loss: 1.0929 - val_categorical_accuracy: 0.7791\n",
      "Epoch 11/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.0159 - categorical_accuracy: 0.8154 - val_loss: 1.0619 - val_categorical_accuracy: 0.7876\n",
      "Epoch 12/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 1.0066 - categorical_accuracy: 0.8215 - val_loss: 1.0551 - val_categorical_accuracy: 0.7791\n",
      "Epoch 13/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 0.9778 - categorical_accuracy: 0.8322 - val_loss: 1.0181 - val_categorical_accuracy: 0.7953\n",
      "Epoch 14/20\n",
      "218/218 [==============================] - 21s 98ms/step - loss: 0.9582 - categorical_accuracy: 0.8353 - val_loss: 1.0074 - val_categorical_accuracy: 0.7907\n",
      "Epoch 15/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 0.9475 - categorical_accuracy: 0.8333 - val_loss: 0.9894 - val_categorical_accuracy: 0.7953\n",
      "Epoch 16/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 0.9228 - categorical_accuracy: 0.8358 - val_loss: 0.9754 - val_categorical_accuracy: 0.7953\n",
      "Epoch 17/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 0.9070 - categorical_accuracy: 0.8438 - val_loss: 0.9624 - val_categorical_accuracy: 0.7946\n",
      "Epoch 18/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 0.8841 - categorical_accuracy: 0.8413 - val_loss: 0.9390 - val_categorical_accuracy: 0.8023\n",
      "Epoch 19/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 0.8816 - categorical_accuracy: 0.8454 - val_loss: 0.9301 - val_categorical_accuracy: 0.8101\n",
      "Epoch 20/20\n",
      "218/218 [==============================] - 21s 97ms/step - loss: 0.8561 - categorical_accuracy: 0.8454 - val_loss: 0.9328 - val_categorical_accuracy: 0.7977\n"
     ]
    }
   ],
   "source": [
    "hist =train_model(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5eabd8ca-27e9-4bdb-afa3-d1ce57cb5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=1e-3, decay=1e-9, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ce601e9-de2b-42f0-aafd-eabe223e1854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/30\n",
      "218/218 [==============================] - 59s 243ms/step - loss: 0.6915 - categorical_accuracy: 0.8259 - val_loss: 0.3615 - val_categorical_accuracy: 0.9023\n",
      "Epoch 2/30\n",
      "218/218 [==============================] - 51s 236ms/step - loss: 0.3128 - categorical_accuracy: 0.9199 - val_loss: 0.2883 - val_categorical_accuracy: 0.9287\n",
      "Epoch 3/30\n",
      "218/218 [==============================] - 52s 237ms/step - loss: 0.2325 - categorical_accuracy: 0.9430 - val_loss: 0.2397 - val_categorical_accuracy: 0.9279\n",
      "Epoch 4/30\n",
      "218/218 [==============================] - 52s 238ms/step - loss: 0.1945 - categorical_accuracy: 0.9566 - val_loss: 0.2073 - val_categorical_accuracy: 0.9388\n",
      "Epoch 5/30\n",
      "218/218 [==============================] - 52s 238ms/step - loss: 0.1681 - categorical_accuracy: 0.9617 - val_loss: 0.1851 - val_categorical_accuracy: 0.9504\n",
      "Epoch 6/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.1302 - categorical_accuracy: 0.9735 - val_loss: 0.1760 - val_categorical_accuracy: 0.9558\n",
      "Epoch 7/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.1270 - categorical_accuracy: 0.9725 - val_loss: 0.1724 - val_categorical_accuracy: 0.9519\n",
      "Epoch 8/30\n",
      "218/218 [==============================] - 52s 238ms/step - loss: 0.1089 - categorical_accuracy: 0.9803 - val_loss: 0.1585 - val_categorical_accuracy: 0.9574\n",
      "Epoch 9/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.1029 - categorical_accuracy: 0.9797 - val_loss: 0.1561 - val_categorical_accuracy: 0.9543\n",
      "Epoch 10/30\n",
      "218/218 [==============================] - 53s 240ms/step - loss: 0.0850 - categorical_accuracy: 0.9860 - val_loss: 0.1478 - val_categorical_accuracy: 0.9589\n",
      "Epoch 11/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0799 - categorical_accuracy: 0.9868 - val_loss: 0.1394 - val_categorical_accuracy: 0.9605\n",
      "Epoch 12/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0804 - categorical_accuracy: 0.9864 - val_loss: 0.1262 - val_categorical_accuracy: 0.9721\n",
      "Epoch 13/30\n",
      "218/218 [==============================] - 52s 240ms/step - loss: 0.0754 - categorical_accuracy: 0.9886 - val_loss: 0.1283 - val_categorical_accuracy: 0.9636\n",
      "Epoch 14/30\n",
      "218/218 [==============================] - 52s 240ms/step - loss: 0.0626 - categorical_accuracy: 0.9925 - val_loss: 0.1243 - val_categorical_accuracy: 0.9651\n",
      "Epoch 15/30\n",
      "218/218 [==============================] - 52s 240ms/step - loss: 0.0610 - categorical_accuracy: 0.9923 - val_loss: 0.1187 - val_categorical_accuracy: 0.9643\n",
      "Epoch 16/30\n",
      "218/218 [==============================] - 53s 241ms/step - loss: 0.0552 - categorical_accuracy: 0.9933 - val_loss: 0.1099 - val_categorical_accuracy: 0.9690\n",
      "Epoch 17/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0513 - categorical_accuracy: 0.9943 - val_loss: 0.1207 - val_categorical_accuracy: 0.9651\n",
      "Epoch 18/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0530 - categorical_accuracy: 0.9911 - val_loss: 0.1192 - val_categorical_accuracy: 0.9690\n",
      "Epoch 19/30\n",
      "218/218 [==============================] - 53s 240ms/step - loss: 0.0482 - categorical_accuracy: 0.9948 - val_loss: 0.1201 - val_categorical_accuracy: 0.9628\n",
      "Epoch 20/30\n",
      "218/218 [==============================] - 53s 240ms/step - loss: 0.0490 - categorical_accuracy: 0.9930 - val_loss: 0.1173 - val_categorical_accuracy: 0.9674\n",
      "Epoch 21/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0515 - categorical_accuracy: 0.9921 - val_loss: 0.1171 - val_categorical_accuracy: 0.9651\n",
      "Epoch 22/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0385 - categorical_accuracy: 0.9958 - val_loss: 0.1031 - val_categorical_accuracy: 0.9729\n",
      "Epoch 23/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0345 - categorical_accuracy: 0.9962 - val_loss: 0.0945 - val_categorical_accuracy: 0.9775\n",
      "Epoch 24/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0293 - categorical_accuracy: 0.9991 - val_loss: 0.0915 - val_categorical_accuracy: 0.9775\n",
      "Epoch 25/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0312 - categorical_accuracy: 0.9972 - val_loss: 0.0932 - val_categorical_accuracy: 0.9760\n",
      "Epoch 26/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0292 - categorical_accuracy: 0.9976 - val_loss: 0.0927 - val_categorical_accuracy: 0.9767\n",
      "Epoch 27/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0319 - categorical_accuracy: 0.9966 - val_loss: 0.0945 - val_categorical_accuracy: 0.9736\n",
      "Epoch 28/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0313 - categorical_accuracy: 0.9974 - val_loss: 0.0962 - val_categorical_accuracy: 0.9729\n",
      "Epoch 29/30\n",
      "218/218 [==============================] - 52s 239ms/step - loss: 0.0288 - categorical_accuracy: 0.9977 - val_loss: 0.0924 - val_categorical_accuracy: 0.9729\n",
      "Epoch 30/30\n",
      "218/218 [==============================] - 53s 241ms/step - loss: 0.0278 - categorical_accuracy: 0.9981 - val_loss: 0.0916 - val_categorical_accuracy: 0.9744\n"
     ]
    }
   ],
   "source": [
    "hist =train_model(epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0573dd0c-5207-4a86-91b3-74f2ccfc1712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_bilin\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./model_bilin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef610099-7289-4580-8f77-afb7c7984288",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model('./model_bilin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c56af12-d66c-4438-80bf-b5c83c37190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\project\\src\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064/2064 [==============================] - 18s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model2.predict_generator(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d3bbeb9-92a0-4cac-9862-13727a8ba361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ...,   4, 257, 257], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_cls_idx = preds.argmax(axis=-1)\n",
    "preds_cls_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0d8c7a0-a091-4a9d-8dba-0a458ce35bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['999999815342', '999999815342', '999999815342', ...,\n",
       "       '999999981399', '999999996239', '999999996239'], dtype='<U12')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_cls = {v: k for k, v in train_generator.class_indices.items()}\n",
    "preds_cls = np.vectorize(idx_to_cls.get)(preds_cls_idx)\n",
    "preds_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca20fbec-6290-4612-bc04-599bed52dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2064"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_lables = []\n",
    "true_lables_upc_idx_map = {}\n",
    "true_lables_img = {}\n",
    "upc_list = os.listdir('../nut_snacks/dataset_split/test/')\n",
    "idx = 0\n",
    "for upc in upc_list:\n",
    "    img_folder = '../nut_snacks/dataset_split/test/' + upc +'/'\n",
    "    img_list = os.listdir(img_folder)\n",
    "    for img in img_list:\n",
    "        true_lables.append(upc)\n",
    "        true_lables_upc_idx_map[idx] = upc\n",
    "        true_lables_img[idx] = img\n",
    "        idx += 1\n",
    "len(true_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77623c26-72de-430d-b7d5-ae609592f32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_predicted = []\n",
    "count = 0\n",
    "for idx in range(0, len(preds_cls)):\n",
    "    if preds_cls[idx] != true_lables[idx]:\n",
    "        wrong_predicted.append(idx)\n",
    "    else:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6004496-04af-4461-a435-b4f511da33a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dc470bd-5d28-43ba-9f9e-79c8fc2a0ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762596899224806"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = count/len(preds_cls)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4098909-42b0-416c-92fa-cfc5284ea871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 49)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_pred_upc = set()\n",
    "for label in wrong_predicted:\n",
    "    wrong_pred_upc.add(true_lables_upc_idx_map[label])\n",
    "len(wrong_pred_upc), len(wrong_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afdbd4c1-5e02-471f-8385-ed0c2f6d3520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_pred_wrong = []\n",
    "for label in wrong_predicted:\n",
    "    images_pred_wrong.append(true_lables_img[label])\n",
    "len(images_pred_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c5c3c98-fc78-43a7-85b7-acec8e1620a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'999999815342': 8,\n",
       " '999999981396': 8,\n",
       " '999999981397': 8,\n",
       " '999999981398': 7,\n",
       " '999999981582': 1,\n",
       " '999999981399': 8,\n",
       " '999999981400': 7,\n",
       " '999999981515': 1,\n",
       " '999999981401': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "for i in range(0 ,len(images_pred_wrong)):\n",
    "    if preds_cls[i] not in d.keys():\n",
    "        d[preds_cls[i]] = 1\n",
    "    else:\n",
    "        d[preds_cls[i]] += 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40a671aa-9cfd-4c7d-a87b-d3e602d9f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../nut_snacks/dataset_split/test/999999981398/walmart-supercenter-1521_16510774_Q02-002_zIK9W--1602-807-1835-1138.jpg 999999815342\n",
      "../nut_snacks/dataset_split/test/999999981400/walmart-supercenter-1518_16559243_Q02-005_fq6tG--2166-470-2456-833.jpg 999999815342\n",
      "../nut_snacks/dataset_split/test/999999981408/walmart-supercenter-1508_16550468_Q02-005_RFZYu--1231-812-1414-983.jpg 999999815342\n",
      "../nut_snacks/dataset_split/test/999999981414/walmart-neighborhood-market-4142_16494957_Q02-002_8Hn4O--2738-2730-2971-3047.jpg 999999815342\n",
      "../nut_snacks/dataset_split/test/999999981417/walmart-neighborhood-market-5855_16497595_Q02-002_XxQ8V--1573-2417-1760-2629.jpg 999999815342\n",
      "../nut_snacks/dataset_split/test/999999981419/walmart-neighborhood-market-5855_16497595_Q02-001_3zRe0--524-3327-737-3698.jpg 999999815342\n",
      "../nut_snacks/dataset_split/test/999999981427/walmart-supercenter-1004_16505800_Q02-003_XkNT5--1048-2853-1200-3121.jpg 999999815342\n",
      "../nut_snacks/dataset_split/test/999999981427/walmart-supercenter-1238_16505805_Q02-004_pLiM6--23-2835-247-3136.jpg 999999815342\n",
      "../nut_snacks/dataset_split/test/999999981430/walmart-2603_16507215_Q02-003_VnZ65--1029-1898-1195-2039.jpg 999999981396\n",
      "../nut_snacks/dataset_split/test/999999981431/walmart-supercenter-1198_16500774_Q02-002_NL315--1441-2711-1585-2895.jpg 999999981396\n",
      "../nut_snacks/dataset_split/test/999999981431/walmart-supercenter-1315_16523858_Q02-001_ay2gI--1334-2690-1509-2945.jpg 999999981396\n",
      "../nut_snacks/dataset_split/test/999999981438/walmart-supercenter-1218_16497506_Q02-001_jgbrN--664-771-721-816.jpg 999999981396\n",
      "../nut_snacks/dataset_split/test/999999981440/walmart-supercenter-147_16507331_Q02-001_UBeWo--1000-1433-1124-1614.jpg 999999981396\n",
      "../nut_snacks/dataset_split/test/999999981445/walmart-2603_16507215_Q02-001_cs8Mg--2565-1723-2700-1943.jpg 999999981396\n",
      "../nut_snacks/dataset_split/test/999999981445/walmart-supercenter-1373_16496132_Q02-001_ZRuSy--372-1515-505-1682.jpg 999999981396\n",
      "../nut_snacks/dataset_split/test/999999981447/walmart-supercenter-1433_16500483_Q02-005_ZULmb--1135-1749-1345-2051.jpg 999999981396\n",
      "../nut_snacks/dataset_split/test/999999981451/walmart-supercenter-1075_16528402_Q02-002_9wvdk--2635-400-2879-783.jpg 999999981397\n",
      "../nut_snacks/dataset_split/test/999999981477/walmart-supercenter-1508_16550468_Q02-003_h35Jk--71-1712-239-1848.jpg 999999981397\n",
      "../nut_snacks/dataset_split/test/999999981486/walmart-neighborhood-market-3153_16501250_Q02-005_idxyN--762-1127-926-1397.jpg 999999981397\n",
      "../nut_snacks/dataset_split/test/999999981486/walmart-supercenter-1077_16494796_Q02-003_rVi2S--433-952-718-1338.jpg 999999981397\n",
      "../nut_snacks/dataset_split/test/999999981497/walmart-supercenter-1207_16516859_Q02-004_qX0VY--435-747-588-870.jpg 999999981397\n",
      "../nut_snacks/dataset_split/test/999999981497/walmart-supercenter-1377_16541855_Q02-003_g6C9H--1282-886-1474-1031.jpg 999999981397\n",
      "../nut_snacks/dataset_split/test/999999981500/walmart-supercenter-1505_16514759_Q02-002_kXpRU--2131-391-2386-782.jpg 999999981397\n",
      "../nut_snacks/dataset_split/test/999999981517/walmart-neighborhood-market-3452_16519598_Q02-004_khFwB--1306-1456-1497-1795.jpg 999999981397\n",
      "../nut_snacks/dataset_split/test/999999981541/walmart-supercenter-1238_16505805_Q02-003_zkR0i--2349-2004-2469-2119.jpg 999999981398\n",
      "../nut_snacks/dataset_split/test/999999981578/walmart-supercenter-1424_16513638_Q02-002_ou7LQ--790-3586-984-3881.jpg 999999981398\n",
      "../nut_snacks/dataset_split/test/999999981580/walmart-neighborhood-market-6966_16507204_Q02-003_NvymB--2536-2874-2751-3165.jpg 999999981398\n",
      "../nut_snacks/dataset_split/test/999999981582/walmart-neighborhood-market-4470_16499718_Q02-004_gZik3--197-2090-376-2356.jpg 999999981398\n",
      "../nut_snacks/dataset_split/test/999999981588/walmart-2603_16507215_Q02-004_xwctM--567-112-922-569.jpg 999999981398\n",
      "../nut_snacks/dataset_split/test/999999981590/walmart-supercenter-1241_16509594_Q02-003_IY08x--2225-1801-2267-1889.jpg 999999981398\n",
      "../nut_snacks/dataset_split/test/999999981674/walmart-supercenter-1241_16509594_Q02-001_zqVHu--1205-1237-1337-1512.jpg 999999981398\n",
      "../nut_snacks/dataset_split/test/999999981680/walmart-supercenter-1080_16507175_Q02-002_gCrZP--1342-3177-1529-3469.jpg 999999981582\n",
      "../nut_snacks/dataset_split/test/999999981689/walmart-2603_16507215_Q02-004_xwctM--396-212-556-544.jpg 999999981399\n",
      "../nut_snacks/dataset_split/test/999999981689/walmart-supercenter-1505_16514759_Q02-003_fH3zy--1677-680-1928-1105.jpg 999999981399\n",
      "../nut_snacks/dataset_split/test/999999981693/walmart-supercenter-1238_16505805_Q02-001_UqNrZ--1689-1764-1883-2132.jpg 999999981399\n",
      "../nut_snacks/dataset_split/test/999999981701/walmart-1365_16527502_Q02-002_wDdVX--1023-761-1255-1032.jpg 999999981399\n",
      "../nut_snacks/dataset_split/test/999999981701/walmart-supercenter-1505_16514759_Q02-002_kXpRU--631-230-969-639.jpg 999999981399\n",
      "../nut_snacks/dataset_split/test/999999981701/walmart-supercenter-1_16495095_Q02-003_ozXU7--1215-2450-1473-2760.jpg 999999981399\n",
      "../nut_snacks/dataset_split/test/999999981758/walmart-supercenter-1310_16499803_Q02-002_AuyJf--245-3075-379-3409.jpg 999999981399\n",
      "../nut_snacks/dataset_split/test/999999981758/walmart-supercenter-1518_16559243_Q02-003_QclLu--2015-2730-2160-3064.jpg 999999981399\n",
      "../nut_snacks/dataset_split/test/999999981860/walmart-supercenter-1505_16514759_Q02-003_fH3zy--0-646-229-985.jpg 999999981400\n",
      "../nut_snacks/dataset_split/test/999999981984/walmart-supercenter-1508_16550468_Q02-005_RFZYu--1930-2053-2058-2307.jpg 999999981400\n",
      "../nut_snacks/dataset_split/test/999999981984/walmart-supercenter-1521_16510774_Q02-003_Qso82--2314-2222-2477-2552.jpg 999999981400\n",
      "../nut_snacks/dataset_split/test/999999981984/walmart-supercenter-1_16495095_Q02-004_8eSVf--2298-1985-2540-2325.jpg 999999981400\n",
      "../nut_snacks/dataset_split/test/999999981985/walmart-supercenter-1_16495095_Q02-001_oFJIU--1273-0-1519-340.jpg 999999981400\n",
      "../nut_snacks/dataset_split/test/999999981998/27.jpg 999999981515\n",
      "../nut_snacks/dataset_split/test/999999996232/walmart-supercenter-1310_16499803_Q02-001_hVgBs--1988-1217-2222-1514.jpg 999999981400\n",
      "../nut_snacks/dataset_split/test/999999996239/walmart-supercenter-1075_16528402_Q02-001_5TX0V--2590-1736-2826-2031.jpg 999999981400\n",
      "../nut_snacks/dataset_split/test/999999996239/walmart-supercenter-1218_16497506_Q02-003_jBy6F--621-698-691-824.jpg 999999981401\n"
     ]
    }
   ],
   "source": [
    "for i in range(0 ,len(images_pred_wrong)):\n",
    "    img ='../nut_snacks/dataset_split/test/' + true_lables_upc_idx_map[wrong_predicted[i]] + '/' + images_pred_wrong[i]\n",
    "    print(img, preds_cls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "688a3b51-8a3f-4277-8311-5d38bb27d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06fab2ab-a6f8-4de8-a0b3-f08ad59fae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(true_lables, preds_cls, average='weighted')\n",
    "precision = precision_score(true_lables, preds_cls, average='weighted')\n",
    "recall  = recall_score(true_lables, preds_cls, average='weighted')\n",
    "accuracy = accuracy_score(true_lables, preds_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a535173-c8a5-4ec4-8539-936532166122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 : 0.9760910297333006\n",
      "precision : 0.9794846948916717\n",
      "recall : 0.9762596899224806\n",
      "accuracy : 0.9762596899224806\n"
     ]
    }
   ],
   "source": [
    "print(\"f1 :\", f1)\n",
    "print(\"precision :\", precision)\n",
    "print(\"recall :\", recall)\n",
    "print(\"accuracy :\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f5817-36eb-4e94-a211-d3e194ba217d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPUEnv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
